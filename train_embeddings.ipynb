{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setting up configurations / settings",
   "id": "7fb3070e0be5d4"
  },
  {
   "cell_type": "code",
   "id": "817179d7a1d5d8f1",
   "metadata": {},
   "source": [
    "# Cell 1: Logging Settings\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cdc97477213db38f",
   "metadata": {},
   "source": [
    "# Cell 2: Load and override config\n",
    "from config import Settings\n",
    "settings = Settings(\n",
    "    MODEL_TYPE=\"word2vec\", # or \"fasttext\"\n",
    "    MODEL_NAME=\"word2vec_enwiki-latest-pages-articles\",\n",
    "    MODEL_RESUME=True, # Existing model from checkpoint if available\n",
    "    DATASET_URL= \"https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2\",\n",
    "    EPOCHS=5, # You can test with fewer epochs\n",
    "    CORPUS_CHECKPOINT_STRATEGY=\"streaming\" # Use \"streaming\" (saved to disk) or \"serialized\" (loaded into RAM)\n",
    ")\n",
    "\n",
    "logging.info(\"Current configuration settings:\\n%s\", settings.model_dump_json(indent=2))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the dataset, run tokenization, and train the model",
   "id": "bcdc24498c04d1e0"
  },
  {
   "cell_type": "code",
   "id": "97ec9c047b4f1999",
   "metadata": {},
   "source": [
    "# Cell 3: If not present, download corpus\n",
    "from utils.download import download\n",
    "from pathlib import Path\n",
    "\n",
    "if not Path(settings.DATASET_PATH).exists():\n",
    "    logging.info(\"Dataset / dump not found. Downloading...\")\n",
    "    download(\n",
    "        url = settings.DATASET_URL,\n",
    "        destination = str(settings.DATASET_PATH)\n",
    "    )\n",
    "    logging.info(f\"Download complete: {settings.DATASET_PATH}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8bdcee31942882b6",
   "metadata": {},
   "source": [
    "# Cell 4: Load Corpus based on Checkpoint Strategy\n",
    "from utils.corpus_loader import load_or_tokenize_wiki\n",
    "from pathlib import Path\n",
    "\n",
    "# Choose the checkpoint file and strategy based on the configuration.\n",
    "match settings.CORPUS_CHECKPOINT_STRATEGY:\n",
    "    case \"serialized\":\n",
    "        corpus_checkpoint = Path(settings.CHECKPOINT_DIR / f\"{settings.MODEL_NAME}.pkl\")\n",
    "        use_streaming = False\n",
    "    case \"streaming\":\n",
    "        corpus_checkpoint = Path(settings.CHECKPOINT_DIR / f\"{settings.MODEL_NAME}.txt\")\n",
    "        use_streaming = True\n",
    "    case _:\n",
    "        raise ValueError(f\"Invalid checkpoint strategy: {settings.CORPUS_CHECKPOINT_STRATEGY}\")\n",
    "\n",
    "# Load or create the corpus based on the chosen strategy.\n",
    "sentences = load_or_tokenize_wiki(\n",
    "    dataset_path=settings.DATASET_PATH,\n",
    "    checkpoint_path=corpus_checkpoint,\n",
    "    use_streaming=use_streaming\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c21588502b581ad",
   "metadata": {},
   "source": [
    "# Cell 5: Train the model (resumes if checkpoint exists)\n",
    "from scripts.train import train_embedding_model\n",
    "\n",
    "model = train_embedding_model(\n",
    "    model_type=settings.MODEL_TYPE,\n",
    "    sentences=sentences,\n",
    "    save_dir=settings.MODEL_DIR,\n",
    "    model_name=settings.MODEL_NAME,\n",
    "    vector_size=settings.VECTOR_SIZE,\n",
    "    window=settings.WINDOW,\n",
    "    min_count=settings.MIN_COUNT,\n",
    "    epochs=settings.EPOCHS,\n",
    "    resume=settings.MODEL_RESUME\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Once loaded, the model can be used / queried, etc",
   "id": "d9d80cefae05975b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T04:12:23.079947Z",
     "start_time": "2025-04-11T04:12:09.403843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import FastText, Word2Vec\n",
    "\n",
    "model_path = settings.MODEL_DIR / f\"{settings.MODEL_NAME}.model\"\n",
    "model_type = settings.MODEL_TYPE.lower()\n",
    "\n",
    "match model_type:\n",
    "    case \"fasttext\":\n",
    "        loaded_model = FastText.load(str(model_path))\n",
    "        print(\"Model loaded successfully\")\n",
    "    case \"word2vec\":\n",
    "        loaded_model = Word2Vec.load(str(model_path))\n",
    "        print(\"Model loaded successfully\")\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported model_type '{model_type}'.\")"
   ],
   "id": "3182e7cb41d08021",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 07:12:09,404 : INFO : loading Word2Vec object from models/word2vec_enwiki-latest-pages-articles.model\n",
      "2025-04-11 07:12:10,242 : INFO : loading wv recursively from models/word2vec_enwiki-latest-pages-articles.model.wv.* with mmap=None\n",
      "2025-04-11 07:12:10,257 : INFO : loading vectors from models/word2vec_enwiki-latest-pages-articles.model.wv.vectors.npy with mmap=None\n",
      "2025-04-11 07:12:10,422 : INFO : loading syn1neg from models/word2vec_enwiki-latest-pages-articles.model.syn1neg.npy with mmap=None\n",
      "2025-04-11 07:12:10,562 : INFO : setting ignored attribute cum_table to None\n",
      "2025-04-11 07:12:22,997 : INFO : Word2Vec lifecycle event {'fname': 'models/word2vec_enwiki-latest-pages-articles.model', 'datetime': '2025-04-11T07:12:22.997860', 'gensim': '4.3.3', 'python': '3.12.9 (main, Mar 31 2025, 00:00:00) [GCC 14.2.1 20250110 (Red Hat 14.2.1-7)]', 'platform': 'Linux-6.13.9-200.fc41.x86_64-x86_64-with-glibc2.40', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "id": "c68035666621e1f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T04:14:08.089173Z",
     "start_time": "2025-04-11T04:14:07.804027Z"
    }
   },
   "source": [
    "# Cell 5: Some basic queries\n",
    "from scripts.evaluate import run_simple_queries\n",
    "\n",
    "run_simple_queries(loaded_model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words for 'music': [('songs', 0.8584167957305908), ('musical', 0.8547187447547913), ('song', 0.8307401537895203), ('soundtracks', 0.8159443736076355), ('duo', 0.8120606541633606), ('soundtrack', 0.7995540499687195), ('lyrics', 0.7965595126152039), ('composer', 0.7955746054649353), ('album', 0.7939282059669495), ('orchestral', 0.7905789017677307), ('pop', 0.7880132794380188), ('dance', 0.7796504497528076), ('singing', 0.7778360247612), ('singers', 0.7772938013076782), ('musically', 0.7719873785972595)]\n",
      "Similarity between 'food' and 'nutrition': 0.77\n",
      "\n",
      "Word that doesn't match in ['fox', 'rabbit', 'motorcycle', 'cat']: motorcycle\n",
      "\n",
      "Vector for 'technology':\n",
      "[-0.4158041  -0.06729489 -0.5843771   0.20349322 -0.546658   -0.21965845\n",
      "  0.24115673 -0.02055575  0.60455126 -0.5004687   0.44455427 -0.04475039\n",
      "  0.50166476 -0.07543188  0.05580118  0.268717   -0.4210576  -0.21334498\n",
      " -0.23160847  0.24778453  0.28523096 -0.088859   -0.42142525  0.32468542\n",
      " -0.02259633  0.4494542   0.19754727  0.1737102  -0.12332408 -0.02844069\n",
      "  0.71625805  0.29779246 -0.45428383 -0.10630906  0.02409134  0.22125182\n",
      " -0.07190704  0.22126354 -0.01829022 -0.7560451  -0.25984424 -0.3377718\n",
      "  0.25861675  0.18048799  0.08531436  0.13358477  0.19378233 -0.20244889\n",
      "  0.03443851 -0.1885853  -0.5748313  -0.16750534  0.08516164 -0.33268163\n",
      " -0.4069837   0.10242354  0.23162083 -0.07196394  0.17565134  0.04883279\n",
      " -0.42662305 -0.19029252  0.23276033  0.36351448  0.23593523  0.39180535\n",
      "  0.53682286  0.13957758  0.02867932  0.16591075 -0.18442057  0.02471038\n",
      " -0.20604171 -0.02507786 -0.48493466 -0.5935342  -0.08371384 -0.3367157\n",
      " -0.34210515  0.29998484  0.19686753 -0.29990363  0.21787065  0.20653673\n",
      "  0.00921837 -0.14844458  0.13256171  0.00902689 -0.14934069  0.04244299\n",
      " -0.11670499  0.2422744   0.12415818  0.28203836 -0.08422409 -0.10074133\n",
      "  0.51492876  0.08071098  0.09170456 -0.1161093 ]\n",
      "\n",
      "Similar words for the vector of 'technology'\n",
      "[('technology', 1.0), ('technologies', 0.84230637550354), ('technological', 0.8389775156974792), ('innovation', 0.8339923620223999), ('science', 0.8308454751968384), ('mechatronics', 0.8112820386886597), ('institute', 0.8013372421264648), ('computer', 0.7998889088630676), ('mtqp', 0.7989289164543152), ('biomedical', 0.7971597909927368)]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 83
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
